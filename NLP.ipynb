{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "752dee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f4fb22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"omw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a13622",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47a120c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence tokens : ['Artificial Intelligence is transforming the world.', 'NLP is a key area of AI.']\n",
      "Word tokens :['Artificial', 'Intelligence', 'is', 'transforming', 'the', 'world', '.', 'NLP', 'is', 'a', 'key', 'area', 'of', 'AI', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "Text = \"Artificial Intelligence is transforming the world. NLP is a key area of AI.\"\n",
    "s_tokens= sent_tokenize(Text)\n",
    "print(f\"Sentence tokens : {s_tokens}\")\n",
    "w_tokens = word_tokenize(Text)\n",
    "print(f\"Word tokens :{w_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9337ed14",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30f444ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed stopwords:['Artificial', 'Intelligence', 'transforming', 'world', '.', 'NLP', 'key', 'area', 'AI', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "w_tokens = [word for word in w_tokens if word.lower() not in stop_words]\n",
    "print(f\"Removed stopwords:{w_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473441b8",
   "metadata": {},
   "source": [
    "## Explain why stopword removal is important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b15d4",
   "metadata": {},
   "source": [
    "Stopword removal is important because it eliminates commonly used words like is, are, the, and in that add little meaning to text.\n",
    "This reduces noise, improves processing speed, and helps NLP models focus on meaningful words that actually affect understanding and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755549e7",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d6e080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "s_words = []\n",
    "for i in w_tokens:\n",
    "    s_words.append(ps.stem(i.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc2794",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af85daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:['Artificial', 'Intelligence', 'transforming', 'world', '.', 'NLP', 'key', 'area', 'AI', '.']\n",
      "Stemmed : ['artifici', 'intellig', 'transform', 'world', '.', 'nlp', 'key', 'area', 'ai', '.']\n",
      "Lemmitized : ['artificial', 'intelligence', 'transform', 'world', '.', 'nlp', 'key', 'area', 'ai', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "l_words = []\n",
    "for i in w_tokens:\n",
    "    l_words.append(wnl.lemmatize(i.lower(),pos='v'))\n",
    "print(f\"Actual:{w_tokens}\")\n",
    "print(f\"Stemmed : {s_words}\")\n",
    "print(f\"Lemmitized : {l_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f26ac",
   "metadata": {},
   "source": [
    "# Difference between them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c92839",
   "metadata": {},
   "source": [
    "* Stemming simply chops off prefixes or suffixes and may produce non-dictionary words, whereas lemmatization returns meaningful, valid dictionary words.\n",
    "\n",
    "* Stemming is fast and rule-based, while lemmatization is slower because it uses vocabulary and grammatical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762fb1b9",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4a0c6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Tags : [('Students', 'NNS'), ('are', 'VBP'), ('learning', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "Sentence = \"Students are learning Natural Language Processing\"\n",
    "tokens = word_tokenize(Sentence)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(f\"Pos Tags : {pos_tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905a19e",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6376eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sundar Pichai → PERSON\n",
      "Google → ORG\n",
      "the United States → GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Sundar Pichai is the CEO of Google and lives in the United States.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\"]:\n",
    "        print(ent.text, \"→\", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7518e9",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb76bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('data', 3), ('science', 1), ('uses', 1), ('to', 1), ('extract', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "text = \"Data science uses data to extract meaningful insights from data\"\n",
    "\n",
    "words = text.lower().split()\n",
    "freq = Counter(words)\n",
    "\n",
    "top_5 = freq.most_common(5)\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac524e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
